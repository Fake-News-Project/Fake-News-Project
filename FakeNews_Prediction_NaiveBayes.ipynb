{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate features from text and use Multinomial Naive Bayes to predict fake news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "* https://github.com/justmarkham/pycon-2016-tutorial/blob/master/tutorial_with_output.ipynb\n",
    "* https://www.youtube.com/watch?v=hXNbFNCgPfY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import newspaper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>authenticity</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>https://www.ice.gov/news/releases/operation-ma...</td>\n",
       "      <td>politico</td>\n",
       "      <td>Operation Matador nets 39 MS-13 arrests in las...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NEW YORK – U.S. Immigration and Customs Enforc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>http://www.politico.com/story/2017/07/27/obama...</td>\n",
       "      <td>politico</td>\n",
       "      <td>Senate Republicans prepare to pass Obamacare r...</td>\n",
       "      <td>['John Bresnahan', 'Burgess Everett', 'Jennife...</td>\n",
       "      <td>Senate Republicans are closing in on passage o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>https://www.nytimes.com/2017/07/26/technology/...</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>Google’s New Parental Control App Has a Flaw: ...</td>\n",
       "      <td>['Brian X. Chen', 'Tech Fix']</td>\n",
       "      <td>“The fact that the kid can graduate themselves...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>http://www.foxnews.com/entertainment/2017/07/2...</td>\n",
       "      <td>foxnews</td>\n",
       "      <td>Hulu resurrects TGIF lineup with acquisition o...</td>\n",
       "      <td>['Tyler Mccarthy']</td>\n",
       "      <td>Hulu is hoping to make itself the go-to stream...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>http://www.npr.org/2017/07/27/539559582/5-unan...</td>\n",
       "      <td>npr</td>\n",
       "      <td>5 Unanswered Questions About Trump's 'Ban' On ...</td>\n",
       "      <td>['Philip Ewing']</td>\n",
       "      <td>5 Unanswered Questions About Trump's 'Ban' On ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url    source  \\\n",
       "2558  https://www.ice.gov/news/releases/operation-ma...  politico   \n",
       "2559  http://www.politico.com/story/2017/07/27/obama...  politico   \n",
       "2560  https://www.nytimes.com/2017/07/26/technology/...   nytimes   \n",
       "2561  http://www.foxnews.com/entertainment/2017/07/2...   foxnews   \n",
       "2562  http://www.npr.org/2017/07/27/539559582/5-unan...       npr   \n",
       "\n",
       "                                                  title  \\\n",
       "2558  Operation Matador nets 39 MS-13 arrests in las...   \n",
       "2559  Senate Republicans prepare to pass Obamacare r...   \n",
       "2560  Google’s New Parental Control App Has a Flaw: ...   \n",
       "2561  Hulu resurrects TGIF lineup with acquisition o...   \n",
       "2562  5 Unanswered Questions About Trump's 'Ban' On ...   \n",
       "\n",
       "                                                 author  \\\n",
       "2558                                                 []   \n",
       "2559  ['John Bresnahan', 'Burgess Everett', 'Jennife...   \n",
       "2560                      ['Brian X. Chen', 'Tech Fix']   \n",
       "2561                                 ['Tyler Mccarthy']   \n",
       "2562                                   ['Philip Ewing']   \n",
       "\n",
       "                                                   text  authenticity  \\\n",
       "2558  NEW YORK – U.S. Immigration and Customs Enforc...             1   \n",
       "2559  Senate Republicans are closing in on passage o...             1   \n",
       "2560  “The fact that the kid can graduate themselves...             1   \n",
       "2561  Hulu is hoping to make itself the go-to stream...             1   \n",
       "2562  5 Unanswered Questions About Trump's 'Ban' On ...             1   \n",
       "\n",
       "      label_num  \n",
       "2558          0  \n",
       "2559          0  \n",
       "2560          0  \n",
       "2561          0  \n",
       "2562          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join('data','merged_data.csv')\n",
    "\n",
    "news_data = pd.read_csv(path,usecols=[1,2,3,4,5,6]) \n",
    "news_data['label_num'] = news_data.authenticity.map({1:0,0:1})\n",
    "\n",
    "news_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop a column\n",
    "#news_data.drop(['authenticity'], axis = 1, inplace = True)\n",
    "#news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1566\n",
       "1     997\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data.label_num.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### balance real and fakenews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample real news\n",
    "number of real news ~= number of fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1002, 7)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced_realnews = news_data[news_data.label_num==0]\n",
    "data_balanced_realnews = data_balanced_realnews.sample(frac=0.64)\n",
    "data_balanced_realnews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get all fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997, 7)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced_fakenews = news_data[news_data.label_num==1]\n",
    "data_balanced_fakenews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine real and fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>authenticity</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>http://www.bighairynews.com/2017/07/military-t...</td>\n",
       "      <td>Bighairynews</td>\n",
       "      <td>Military Trannies Trumped</td>\n",
       "      <td>[]</td>\n",
       "      <td>WASHINGTON (World News Bureau) - President Tru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>http://bipartisanreport.com/2017/07/27/scaramu...</td>\n",
       "      <td>bipartisanreport</td>\n",
       "      <td>Scaramucci Responds To Article About His Profa...</td>\n",
       "      <td>['Holly Lee']</td>\n",
       "      <td>Anthony Scaramucci is facing serious scorn aft...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>https://amgreatness.com/2017/07/19/muellers-in...</td>\n",
       "      <td>wordpress</td>\n",
       "      <td>Mueller’s Investigation Must Be Limited and Ac...</td>\n",
       "      <td>['Andrew C. Mccarthy', 'Sam Mcgowan', 'Bill S'...</td>\n",
       "      <td>How much goalpost moving should be tolerable i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>http://www.politico.com/story/2017/07/26/scara...</td>\n",
       "      <td>wordpress</td>\n",
       "      <td>Scaramucci still stands to profit from SkyBrid...</td>\n",
       "      <td>['Lorraine Woellert', 'Cristiano Lima', 'Tara ...</td>\n",
       "      <td>The incoming White House communications direct...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>http://beforeitsnews.com/health/2017/07/how-po...</td>\n",
       "      <td>beforeitsnews</td>\n",
       "      <td>How potatoes can increase the risk of cancer c...</td>\n",
       "      <td>['Natural Health']</td>\n",
       "      <td>(Before It's News)\\n\\n(NaturalHealth365) A rec...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url            source  \\\n",
       "1994  http://www.bighairynews.com/2017/07/military-t...      Bighairynews   \n",
       "1995  http://bipartisanreport.com/2017/07/27/scaramu...  bipartisanreport   \n",
       "1996  https://amgreatness.com/2017/07/19/muellers-in...         wordpress   \n",
       "1997  http://www.politico.com/story/2017/07/26/scara...         wordpress   \n",
       "1998  http://beforeitsnews.com/health/2017/07/how-po...     beforeitsnews   \n",
       "\n",
       "                                                  title  \\\n",
       "1994                          Military Trannies Trumped   \n",
       "1995  Scaramucci Responds To Article About His Profa...   \n",
       "1996  Mueller’s Investigation Must Be Limited and Ac...   \n",
       "1997  Scaramucci still stands to profit from SkyBrid...   \n",
       "1998  How potatoes can increase the risk of cancer c...   \n",
       "\n",
       "                                                 author  \\\n",
       "1994                                                 []   \n",
       "1995                                      ['Holly Lee']   \n",
       "1996  ['Andrew C. Mccarthy', 'Sam Mcgowan', 'Bill S'...   \n",
       "1997  ['Lorraine Woellert', 'Cristiano Lima', 'Tara ...   \n",
       "1998                                 ['Natural Health']   \n",
       "\n",
       "                                                   text  authenticity  \\\n",
       "1994  WASHINGTON (World News Bureau) - President Tru...             0   \n",
       "1995  Anthony Scaramucci is facing serious scorn aft...             0   \n",
       "1996  How much goalpost moving should be tolerable i...             0   \n",
       "1997  The incoming White House communications direct...             0   \n",
       "1998  (Before It's News)\\n\\n(NaturalHealth365) A rec...             0   \n",
       "\n",
       "      label_num  \n",
       "1994          1  \n",
       "1995          1  \n",
       "1996          1  \n",
       "1997          1  \n",
       "1998          1  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced = pd.concat([data_balanced_realnews, data_balanced_fakenews], ignore_index=True)\n",
    "data_balanced.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1002\n",
       "1     997\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced.label_num.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert text to numbers (features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define x and y for modeling later, and split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999,)\n",
      "(1999,)\n"
     ]
    }
   ],
   "source": [
    "x = data_balanced.text\n",
    "y = data_balanced.label_num\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1499,)\n",
      "(500,)\n",
      "(1499,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    752\n",
       "0    747\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customized tokenize function for stemming and removing punctuation\n",
    "codes are taken from https://stackoverflow.com/questions/26126442/combining-text-stemming-and-removal-of-punctuation-in-nltk-and-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize_stemmer(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [i for i in tokens if i not in string.punctuation]\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Use CountVectorizer to generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer(tokenizer=tokenize_stemmer,stop_words='english',ngram_range=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(2, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenize_stemmer at 0x30b9ded08>,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1499x422215 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 551598 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_dtm = vect.transform(x_train)\n",
    "# examine the document-term matrix\n",
    "x_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_dtm.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<500x422215 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 62009 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "x_test_dtm = vect.transform(x_test)\n",
    "x_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: use TF-IDF to generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(2, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenize_stemmer at 0x3388e4e18>, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize_stemmer,stop_words='english',ngram_range=(2, 2))\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1499x422215 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 551598 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_dtm = tfidf.fit_transform(x_train)\n",
    "\n",
    "# examine the document-term matrix\n",
    "x_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<500x422215 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 62009 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_dtm = tfidf.transform(x_test)\n",
    "x_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting fake news using Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.5 ms, sys: 10.2 ms, total: 32.7 ms\n",
      "Wall time: 31.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(x_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91800000000000004"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make class predictions for x_test_dtm\n",
    "y_pred_class = nb.predict(x_test_dtm)\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "metrics.accuracy_score(y_test, y_pred_class) # or nb.score(x_test_dtm,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[229,  26],\n",
       "       [ 15, 230]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the false positives (real news incorrectly classified as fake)\n",
    "x_test[y_test < y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example false positives\n",
    "#x_test[1747]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the false negatives (fake news incorrectly classified as real)\n",
    "x_test[y_test > y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example false negative\n",
    "# x_test[2096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate predicted probabilities for x_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(x_test_dtm)[:, 1]\n",
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predicting fake news using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 109 ms, sys: 9.42 ms, total: 118 ms\n",
      "Wall time: 117 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm\n",
    "%time logreg.fit(x_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91000000000000003"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = logreg.predict(x_test_dtm)\n",
    "\n",
    "# calculate accuracy\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
